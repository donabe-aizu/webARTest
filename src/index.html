<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8"/>
  <title>Babylon.js WebXR ImageTracking Sample</title>
  <script src="https://cdn.babylonjs.com/babylon.js"></script>
  <script src="https://cdn.babylonjs.com/gui/babylon.gui.min.js"></script>
  <!-- WebXR ポリフィルが必要な場合は追加 -->
  <!-- <script src="https://cdn.jsdelivr.net/npm/webxr-polyfill@latest/build/webxr-polyfill.min.js"></script> -->
</head>
<body style="margin: 0; padding: 0; overflow: hidden;">
<canvas id="renderCanvas" touch-action="none" style="width: 100%; height: 100%;"></canvas>

<script>
  // ページ読み込み後に実行
  window.addEventListener("DOMContentLoaded", async function () {
    const canvas = document.getElementById("renderCanvas");

    // Babylon.js エンジン作成
    const engine = new BABYLON.Engine(canvas, true);

    // シーン生成関数
    const createScene = async function () {
      const scene = new BABYLON.Scene(engine);

      // XRセッション開始時に VR/AR 用のカメラは自動的に生成されるので
      // ここではデバッグ用のカメラを作成(PCで試せるように)
      const camera = new BABYLON.ArcRotateCamera("camera", 
        Math.PI / 2, Math.PI / 4, 3, BABYLON.Vector3.Zero(), scene);
      camera.attachControl(canvas, true);

      // 簡易的な照明
      const light = new BABYLON.HemisphericLight("light", 
        new BABYLON.Vector3(0, 1, 0), scene);
      light.intensity = 1.0;

      // XR 体験を簡単に構築するヘルパー
      const xr = await scene.createDefaultXRExperienceAsync({
        // AR セッションを使うため "immersive-ar"
        // 参照空間は多くの場合 "local" や "local-floor" を用いる
        uiOptions: {
          sessionMode: "immersive-ar",
          referenceSpaceType: "local",
        },
        optionalFeatures: [
          "hit-test",        // 必要に応じて追加
          "anchors",         // 必要に応じて追加
          "plane-detection", // 必要に応じて追加
          "image-tracking"   // ★ これが重要
        ],
      });

      // XR 機能マネージャを取得
      const featuresManager = xr.baseExperience.featuresManager;

      // ImageTracking の有効化
      // "latest" の代わりに "stable" が使える場合もありますが、ブラウザ実装状況によって異なります。
      const imageTracking = featuresManager.enableFeature(
        BABYLON.WebXRFeatureName.IMAGE_TRACKING,
        "latest",
        {
          // 認識させたい画像を配列形式で指定
          // estimatedRealWorldWidth には、画像が実世界でどの程度の大きさか(メートル単位)を推定値で指定
          images: [
            {
              src: "donabe.png", 
              estimatedRealWorldWidth: 0.2, // 画像の実サイズ(メートル)
            }
          ]
        }
      );

      // 認識中/追跡中の画像に関するイベント
      // trackedImages[0], onTrackedImageUpdatedObservable を使って状態を監視できる
      imageTracking.onTrackedImageUpdatedObservable.add((trackedImage) => {
        // trackedImage.index や trackedImage.version などで
        // どの画像の状態か確認可能 (上の images[] で複数指定した場合)
        if (trackedImage.isTracked) {
          // 画像がトラッキングされている状態
          console.log("Image index:", trackedImage.index, " is tracked.");
        } else {
          // 画像が見つからなくなった場合など
          console.log("Image index:", trackedImage.index, " lost tracking.");
        }
      });

      // 3D オブジェクトを作成して、Transform Node に関連付け
      // trackedImages配列の各要素に transformNode が割り当てられるため、
      // そこを親にすれば、画像と一緒にオブジェクトが動く
      imageTracking.onAddedObservable.add((trackedImage) => {
        // Box の例
        const box = BABYLON.MeshBuilder.CreateBox("box" + trackedImage.index, 
          { size: 0.1 }, scene);
        
        // 画像の transformNode を親に設定 (画像を基準に動くようになる)
        box.setParent(trackedImage.transformNode);

        // 視認しやすいよう簡単なマテリアル設定 (色変更など)
        const mat = new BABYLON.StandardMaterial("matBox", scene);
        mat.diffuseColor = new BABYLON.Color3(1, 0, 0); // 赤
        box.material = mat;
      });

      return scene;
    };

    const scene = await createScene();

    // レンダーループ
    engine.runRenderLoop(function () {
      scene.render();
    });

    // リサイズ対応
    window.addEventListener("resize", function () {
      engine.resize();
    });
  });
</script>
</body>
</html>
